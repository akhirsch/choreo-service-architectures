%!TEX root = desc.tex

%thrust1
\subsection{Thrust 1: Polymorphism-Enabled Features}
\label{sec:t1}

The first thrust of this work will design new features for choreographic languages
that rely on first-class process polymorphism and
are needed to substantially broaden the range of possible choreographic applications.

\subsubsection{Spawning New Processes}
\label{sec:spawning}

The first feature is the ability to launch and terminate new processes---computational units representing threads, processes, nodes, etc---% DO NOT DELETE, COMMENT IS IMPORTANT FOR SPACING
a core feature of many concurrent systems.
A few early choreographic works recognized its importance~\citep{CarboneM13,CruzFilipeM16a},
but those works lacked critical features for realistic programming, like higher-order operations,
and required processes to be spawned only to execute specific pre-defined operations.

We propose a much more general structure, where there is little distinction between an existing process and a newly-spawned one,
and threads may exit when they are no longer needed.
Moreover, we will integrate this dynamic process management with a host of modern choreographic advances,
including higher-order functions and process polymorphism.

\begin{example}{Dynamic Thread Pool}
Many systems incorporate thread pools that dynamically resize based on demand.
That is, at high-demand times when requests are regularly waiting on threads, they spawn more,
and at low-demand times when threads are regularly sitting idle, excess threads are killed.
The proposed work would allow us to implement such thread pools as choreographies
with code akin to the following, where~$F$ is a local thunk provided by the client~$\Client$
specifying the computation to run.
\[
  \addtocounter{numlevels}{1}
  \Fun{\programfont{runJob}}{F}{
%    \LetInRaw*{
%      \begin{array}[t]{@{}l@{}}
%        T \ChorDef \ITE*{\Mngr.\programfont{enoughWorkers()}}
%                        {(\Mngr.\programfont{selectWorker}() \ColSend \Client)}
%                        {(\Mngr.\ChorFont{spawn} \ColSend \Client)} \\
%        T.f \ChorDef F \ColSend T \\
%        \Client.\mathit{res} \ChorDef T.(f~()) \ColSend \Client
%      \end{array}
%    }{
%      \Client.\text{``}\programfont{done}\text{''} \ColSend \Mngr \seq
%      \Mngr.\programfont{releaseOrKillWorker}(T) \seq
%      \Client.\mathit{res}
%    }
    \LetMany{{T}{\ITE*{\Mngr.\programfont{enoughWorkers()}}{\Mngr.\programfont{selectWorker}() \ColSend \Client}{\Mngr.\ChorFont{spawn} \ColSend \Client}}%
             {T.f}{F \ColSend T}%
             {\Client.\mathit{res}}{T.(f~()) \ColSend \Client}}{%
      \Client.\text{``}\programfont{done}\text{''} \ColSend \Mngr \seq
      \Mngr.\programfont{releaseOrKillWorker}(T) \seq
      \Client.\mathit{res}
    }
  }
  \addtocounter{numlevels}{-1}
\]

The PIs recent work on first-class process polymorphism showed how to
implement \emph{static} thread pools with a fixed set of threads~\citep{SamuelsonHC25}.
However, that work assumes the set of threads in the entire system is fixed,
inherently preventing dynamically resizing the thread pool.
\end{example}

Safely spawning and terminating processes in a choreography---be they threads, system processes, or entire nodes---poses three distinct problems,
all illustrated by the above example.
\begin{enumerate}
  \item\label{spawn:li:name}
    Existing processes must be made aware of the new one in a way that allows them to interact with it.
    Otherwise the new process cannot send or receive messages, meaning they cannot participate in the choreography in any meaningful way.

    \textit{Example:} Clients of newly-spawned threads must know where to send their jobs.

  \item\label{spawn:li:kill}
    If a process terminates, living processes must know not to send to or receive from the terminated process.
    A retained reference to a dead name can result in a live process attempting to contact a dead one, producing deadlock.

    \textit{Example:} The pool manager and clients must properly discard all references to a killed thread.

  \item\label{spawn:li:code}
    The new process must know what code to execute, and it must match the code existing nodes expect.
    Without the correct code, the new process and existing processes might not have matching message sends and receives, causing deadlock.

    \textit{Example:} New threads must know to wait for instructions from a client and execute them
    and reply with the result, or the client will deadlock.
\end{enumerate}

Problem~\ref{spawn:li:name} is immediately solved by first-class process polymorphism.
Upon spawning a new thread, we give it a new name and bind that name to a process variable.
That process now functions just as any other polymorphic process variable;
it can be transmitted across the network or used as an endpoint for sending and receiving messages.
Problems~\ref{spawn:li:kill} and~\ref{spawn:li:code}---both of which can cause deadlock if not properly addressed---require additional research.

A key insight is that Problem~\ref{spawn:li:kill} closely resembles classic memory management concerns.
Just as memory should not be referenced after being freed, lest the application crash or expose critical security vulnerabilities,
processes should not be referenced after they terminate, lest the application deadlock.
Similarly, if a process's computation has completed, it should terminate to avoid leaking resources,
just memory processes should be freed when their values are no longer needed.

There are, however, two important differences between our setting and traditional memory management.
Making our setting simpler is that, unlike values in memory which can themselves contain memory addresses,
process names are opaque and it is the top-level code that refers to them.
We therefore have no need for the sort of reachability analysis employed by many automatic memory management systems.
Indeed, simple reference counting would be sufficient to determine when no more code references a spawned process.
Making our setting considerably more challenging, however, is Problem~\ref{spawn:li:code} mentioned above:
new processes must know what code to execute.
With an entirely dynamic lifetime, it is not clear what code a new process will need or how to determine that when spawning it.

We propose to investigate how various automatic memory-management strategies translate to the context of spawned-choreographic-process management.
In particular, we have substantial preliminary results showing the plausibility of scope-based lifetimes.
We will also investigate other techniques, including reference counting---simplified in our setting---and Rust-style linearity
to control aliasing and more directly identify inaccessible processes.

\begin{goal}
  \label{goal:spawn}
  Design and implement dynamic process spawning and termination in choreographies while maintaining deadlock-freedom guarantees.
\end{goal}

\paragraph{Preliminary Work: Scoped Processes}
Preliminary work by both PIs
has shown that basing the lifetime of a spawned process on a syntactic scope in the choreography is a viable approach.
In particular, syntactic scoping provides a simple solution to Problem~\ref{spawn:li:code}:
the code for a spawned thread~$T$ is simply the $T$-projection of the code for which it is in scope.

In the thread pool example, if there are too many requests, the pool manager could easily spawn a new thread
to process an individual request and that thread would automatically die after processing is complete.
The code for this case might look as follows.
As above, $F$~is a local thunk specifying~\Client's computation.
\[
  \addtocounter{numlevels}{1}
  \ForkIn{\Mngr}{T \ColSend \Client}{%
    \LetMany{{T.f}{F \ColSend T}{\Client.\mathit{res}}{T.(f~()) \ColSend \Client}}
            {\Client.\mathit{res}}
  }
  \addtocounter{numlevels}{-1}
\]
In this code, the pool manager~$\Mngr$ forks a new thread,
binds its name to the process variable~$T$, and sends it to the client~$\Client$.
The client then sends its job to~$T$ who runs it and passes the result back to~$\Client$.

Just as scoped memory management must ensure that references do not escape their scope through aliases or closures,
we also need to ensure references to~$T$ remain confined.
%Just as alias analysis is important to scope-based memory management,
%we also need to ensure references to~$T$ do not escape the scope in which the thread is alive.
%Ensuring that~$T$ is only referenced while it is alive is more complicated.
%While the scoping provides a syntactic boundary for when such a reference is safe,
%it does not automatically guarantee that no thread can attempt to reference~$T$ after it dies.
Consider the following choreography that forks a process and returns a function closing over its name: $\ForkIn{\Alice}{T}{\LamN \_\ldotp \Alice.42 \ColSend T}$.
This function, if applied, would immediately cause deadlock, as~\Alice attempts to send~$42$ to a thread that is no longer running.

Our preliminary work indicates that we can resolve this dilemma by tracking the processes involved in a function
and verifying that any function returned from a~\ForkN block does not reference the spawned process.
Specifically, augmenting function types with the set of processes needed to compute the function
allows the typing rule for~\ForkN to verify that those processes are all in scope---and thus alive---outside the~\ForkN block.
Since process-name variables are immutable, aliasing a name to a variable in a larger scope is not possible,
so addressing the closure concern in this way solves the problem.

\paragraph{Proposed Work: Spawned Processes with Unbounded Lifetimes}
Our scope-based preliminary work provides a clean way to identify what code to provide a new process
and makes clear that \emph{some} form of process spawning is viable, it is not without drawbacks.
In particular, it is unable to handle new processes with indefinite lifetimes.
For example, the thread pool may not wish to spawn additional threads only for a single task,
but instead simply increase the pool capacity when demand is high
and be willing to kill any thread that happens to be idle when demand is low.

To support this more-flexible mode of dynamic processes, we will investigate how other memory management techniques
transfer into the choreographic process-management domain.
We will especially focus on how to provide the correct code to new processes with no static bound on their lifetime.
Two promising approaches are (1)~to give new processes a view of the entire application code,
and (2)~restrict new processes to specific behavior fixed when they are spawned.
The first option would require existing processes to keep extra copies of the entire application code if they are able to initiate a spawn.
The second would need static verification that existing processes only attempt to interact with a newly spawned process
in accordance with the code that new process is provided, which would require statically tracking what different processes can do.

\subsubsection{Message Multi-Receives}
\label{sec:multi-receive}

The second new feature is a generalization of receiving a message that allows one recipient to receive multiple messages.
Existing choreographies allow a single process to \emph{send} messages to multiple recipients in a single (choreographic) instruction~\citep{BatesK+25,SamuelsonHC25} (a broadcast),
but no choreographies allow a single process to \emph{receive} messages from multiple senders as a single operation.

If we require all of the messages to arrive, this acts precisely the same as the gather operation in the Message Passing Interface~\cite{MPIForum93}.
However, the power of this primitive becomes apparent when we require only a subset of the messages to arrive before the recipient can continue.
This is a fundamental primitive---currently missing from the choreographic literature---that is necessary to build many systems,
including distributed consensus protocols like Paxos~\citep{Lamport98}.
In such protocols, each node waits for votes from all others,
but must be able to continue once messages from half of the other nodes have arrived.

To accomplish this goal, we will add a new syntactic form to choreographies:
\[
  \{\ell_1.e_1, \dotsc, \ell_n.e_n\} \multircv{k} \ell
\]
This term indicates that processes $\ell_1, \dotsc, \ell_n$ should run computations~$e_1, \dotsc, e_n$, respectively, and send the resulting values to~$\ell$.
Process~$\ell$ can then accept those messages in any order and should continue executing once~$k$ of them arrive.
Instead of getting a single value, as in normal message passing, $\ell$~will receive a list of~$k$ values, one for each message.

Most applications of this feature fundamentally rely on process polymorphism.
When~$\ell$ receives its list of~$k$ messages, it must be able to identify who sent those messages
to be able to respond or even simply record which ones arrived.
With first-class process polymorphism, identifying the sender is simple;
the message list from the multi-receive contains not just the value of each message, but a sender--value pair for each.

\paragraph{Message-Based Triggered Events}
Some applications---like Byzantine fault tolerant~(BFT) consensus protocols---wait not just for a fixed number of messages,
but for messages that satisfy a more complicated condition---like enough messages \emph{with the same value}.
The above-proposed multi-receive is powerful, but is not expressive enough to implement this functionality.
We propose to further empower these multi-receive operations by extending them to support \emph{triggered events}.

A triggered event consists of two components:
a predicate over a message list that determines when the event triggers,
and a computation to run when the predicate is satisfied.
Triggered events will be specified using the following switch-like syntax.
\[
  \{\ell_1.e_1, \dotsc, \ell_n.e_n\} \ColSend \ell ~\ChorFont{for~triggers}~ (P_1 \Rightarrow C_1) \dotsb (P_k \Rightarrow C_k)
\]
Here $P_1, \dotsc, P_k$ are the predicates and $C_1, \dotsc, C_k$ are choreographies
specifying which computation to perform when the corresponding event triggers.
Note that these are full choreographies, meaning they can involve computation by processes other than~$\ell$,
but only~$\ell$ inherently knows which event triggered.
Much like choreographic conditional statements, this creates a knowledge of choice problem~\citep{Montesi23}.
that selects between an arbitrary set of triggers, rather than only a two-way conditional branch.

Note that trigger events are a strict generalization of the $k$-of-$n$ multi-receives proposed above.
We can implement $\{\ell_1.e_1, \dotsc, \ell_n.e_n\} \multircv{k} \ell$ using triggers as
\[
  \{\ell_1.e_1, \dotsc, \ell_n.e_n\} \ColSend \ell ~\ChorFont{for~triggers}~ ((\programfont{length}~\mathit{msgs}) \geq k \Rightarrow \ell.\mathit{msgs}).
\]
However, the triggered events are considerably more expressive.
A node in a BFT consensus protocol with the~$3f + 1$ nodes---the minimum to tolerate~$f$ failures---might trigger a commit
when it receives~$f + 1$ votes for the same value.
With dishonest nodes, that could occur as soon as $f + 1$ messages arrive, or as late as $2f + 1$ messages.
Triggered events will thus provide developers a means to specify these conditions and allow nodes to proceed immediately when they are satisfied.

We will explore several different aspects of triggered events.
First, we will investigate how to specify the predicates.
Predicates should be able to examine both process names and values that have arrived,
making the local language of the choreography and obvious choice.
However, it is not clear how the system should behave if a trigger predicate fails to terminate.
We will therefore investigate if there are appropriate terminating languages for specifying predicates.

A second question arises when predicates are not mutually exclusive.
What should happen if multiple predicates are satisfied?
The choreography could execute only the first event to trigger,
and either choose nondeterministically if multiple triggers are satisfied simultaneously
or require the choreography to specify a priority order.
It could also execute all triggered events in some order.
We will investigate which of these options is most appropriate,
both by assessing their technical complexity and by surveying a variety of concurrent applications to determine their value to developers.

\begin{goal}
  \label{goal:multirecv}
  Design and implement a multi-receive feature for choreographies
  where the recipient can proceed before all messages have arrived,
  including by defining custom triggered events.
\end{goal}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "desc.tex"
%%% End:
