%thrust2
\subsection{Thrust 2 - Improved Compilation for Process Polymorphism}
\label{sec:t2}

\iffalse
\begin{outline}{Thrust 2 Outline}
\item Current status of Process Polymorphism
  \begin{lvl}
  \item Trick in EPP: Autognosis
    \begin{lvl}
    \item Every process knows its own identity
    \end{lvl}
  \item Formalized as $\AmIinN$
    \begin{lvl}
    \item Branches depending on whether the current process is in some set
    \end{lvl}
  \item Current state of the art: \emph{every} process-polymorphic function introduces $\AmIinN$ everywhere.
  \end{lvl}
\item Critique
  \begin{lvl}
  \item Every process-polymorphic function has its code doubled
    \begin{lvl}
    \item Can lead to expondential blowup of code size
    \item Linear cost to performance
    \end{lvl}
  \item This seems to be inherent for worst-case
    \begin{lvl}
    \item Random paths example
    \end{lvl}
  \item Often, it is unnecessary
  \end{lvl}
\item Goal: Cheap Process Polymorphism
  \begin{lvl}
  \item Static analyis
    \begin{lvl}
    \item Must
    \item Might
    \end{lvl}
  \item Switch-case $\programfont{AmI}\mathord{\in}\programfont{?}$
    \begin{lvl}
    \item Make statically-known disjoint sets flat
    \item Do they need to be disjoint?
      \begin{lvl}
      \item First-match semantics
      \end{lvl}
    \end{lvl}
  \end{lvl}
\item Experimental Verification of Efficiency Gains
  \begin{lvl}
  \item Goal: Develop benchmarks for process polymorphic EPP
    \begin{lvl}
    \item Contains worst-case example
    \item Contains examples that our techniques can optimize
    \item Contains ``representative'' examples
    \end{lvl}
  \item Goal: Build new EPP into compiler
    \begin{lvl}
    \item Undergraduate training
    \item Prior Work
    \end{lvl}
  \item Results of our benchmark
    \begin{lvl}
    \item Goal: Experimentally verify our optimizations are useful in practice.
    \end{lvl}
  \end{lvl}
\end{outline}
\fi

As mentioned above, choreographic programs are compiled through an operation known as \emph{endpoint projection~(EPP)}, which extracts a program for each participant in the system.
To implement process polymorphism, EPP relies on the principle of \emph{autognosis}: every participant knows their own identity.
This is formalized in the network language via a primitive $\AmIN$ operation,
which branches based on the relationship between the current party and a given value.
For instance, $\AmI{\ell}{C_1}{C_2}$ means ``if the party running this program has name~$\ell$, run~$C_1$, otherwise run~$C_2$.''
The PIs have generalized this to \AmIinN, which tests if the running program's name is in a given set~\citep{SamuelsonHC25}.

In current choreographic theory, \emph{every} process-polymorphic function starts with as many $\AmIN$/$\AmIinN$ operations as there are process parameters.
This approach can produce an exponential blowup in code size---the projection of a process-polmorphic function with~$k$ process parameters will have $2^k$ copies of the code.
Moreover, these branches have a (small) cost at runtime, leading to a linear performance cost.

In the worst case, this cost in both code size and performance appears inherent.
For instance, consider the following choreographic pseudocode:
\newcommand{\RandSets}{\programfont{randomSubsets}}
\[
%  \def\arraystretch{1.1}
%  \newcommand{\Weird}{\programfont{weird}}
%  \begin{array}{l}
%    (\rho_1, \rho_2) \ChorDef \programfont{randomSplit}(\{\Alice, \Bob, \Cathy, \Dave\}) \\
%    \Weird \ChorDef \TLamN (\alpha, \beta)\ldotp (\alpha.1, \beta.2) \\
%    \ITE{\programfont{flip}()}{\Weird(\rho_1, \rho_2)}{\Weird(\rho_2, \rho_1)}
%  \end{array}
  \LetIn{(\rho_1, \rho_2, \rho_3)}{\RandSets(\{\Alice, \Bob, \Cathy, \Dave\})}{(\rho_1.1, \rho_2.2, \rho_3.3)}
\]
This program randomly splits the set of participants $\{\Alice, \Bob, \Cathy, \Dave\}$ into three dynamic sets, $\rho_1$,~$\rho_2$, and~$\rho_3$, potentially with overlap.
For each of~$i = 1, 2, 3$, locations in~$\rho_i$ produce the value~$i$.
%Locations in~$\rho_1$ then produce the value~$1$ and locations in~$\rho_2$ produce~$2$.
%It then randomly chooses one of these two dynamic sets to get the value $1$, while the other gets the value $2$.
Since any participant could end up in any~$\rho_i$ independently, and which set they are in is only determined at runtime, everyone must have eight code paths:
one for each possible combination of being in~$\rho_1$, $\rho_2$, and/or~$\rho_3$.
%one each for when they are in only~$\rho_1$, only~$\rho_2$, both, or neither.

While this example shows that the current (na\"ive) solution is optimal in some cases, it is not always.
In fact, relatively common use cases of process polymorphism only select between a few possible inputs.
We can already see this in the above example.
A process $\LocFont{E}$ that is not any of~\Alice, \Bob, \Cathy, or~\Dave does \emph{not} need multiple code paths.
We statically know it cannot be in any of~$\rho_1$,~$\rho_2$, or~$\rho_3$.
Similarly, if we replaced \RandSets with a partitioning function,
\Alice,~\Bob, \Cathy, and~\Dave would each only need three code paths.
This leads to the following goal:
\begin{goal}
  Create an optimized version of endpoint projection,
  allowing for smaller program sizes and better run-time performance in common cases.
\end{goal}

To achieve this goal, we propose to employ static analysis to determine which participants a name might represent and which participants might be in a set.
In the example above, \RandSets is provided the constant set $\{\Alice, \Bob, \Cathy, \Dave\}$ as an argument,
so those are the only locations that can be in~$\rho_1$, $\rho_2$, and~$\rho_3$.
Note that tracking this information through polymorphic function calls becomes considerably more complicated.

We propose to investigate multiple static analysis techniques in the literature that appear suited to provide the information needed for this optimization.
In particular, abstract interpretation~\todo{cite Cousot and Cousot?}, type-and-effect systems~\todo{cite},
and refinement types~\todo{cite} can all track which locations might be in a given set.
We plan to investigate each as possibilities.
By providing EPP with information about which locations might be in each set,
we can optimize the projection to only produce necessary \AmI statements,
avoiding both code blowup and unnecessary performance costs.

%To achieve this goal, we will need to employ static analysis to determine which participants a name might represent and which participants might be in a set.
%In the case of the example above, we know that only the four participants $A$, $B$, $C$, and $D$ could possibly be in $\rho_1$ and $\rho_2$.
%Moreover, since \programfont{weird} is only called with $\rho_1$ and $\rho_2$ as arguments, $X$ and $Y$ have the same restrictions.
%(Note that this requires knowledge about the entire scope of \programfont{weird}: without that knowledge, $X$ and $Y$ could include any participant.)
%Several static analysis methods in the literature seem to be able to give us the information required for this optimization.
%In particular, abstract interpretation and type-and-effect systems both seem to be plausible candidates.
%We plan to investigate both as possibilities.
%Once we have the information about who \emph{could} be represented by a name/set of names, we can then use that during projection to only project \AmIN instructions when necessary.
%This will prevent code blowup in many cases, as well as linear costs that do not need to be paid.

Even when \AmIN is necessary, however, we may be able to simplify deeply-nested branching structures into a single multi-way \AmI
analogous to \programfont{switch}--\programfont{case} flattening multi-branch \programfont{if} statement.
%Even when we do need an \AmIN instruction, however, we may be able to do better by allowing multi-way \AmIN expressions analogous to \programfont{switch} statements vis-a-vis \programfont{if} statements.
For instance, the body of the \LetN in the above example could project to the following.
\[
  \AmIinN ~\begin{array}[t]{@{}l@{}}
    {}\mid \rho_1 \cap \rho_2 \cap \rho_3 \Rightarrow (1, 2, 3) \\
    {}\mid \rho_1 \cap \rho_2 \Rightarrow (1, 2) \\
    \quad \vdots \\
    {}\mid \rho_2 \Rightarrow (2) \\
    {}\mid \rho_3 \Rightarrow (3) \\
    {}\mid \_ \Rightarrow () \\
  \end{array}
\]
While this may not provide significant benefit for this intentionally-contrived worse-case example,
its value becomes more clear when we replace \RandSets with a partitioning function.
In that situation, we statically know that every intersection $\rho_i \cap \rho_j = \varnothing$ when $i \neq j$.
No location is in~$\varnothing$ allowing immediate elimination of four of the eight branches of the \AmIinN.

\ethan{
  I was having trouble buying that the switch-case formulation is actually different from the first optimization.
  I tried to tie it together as an important component of implementing it properly.
}

\ethan{Structurally, I'm mostly fine with the stuff below this line, but I haven't edited any of it yet.}
\vspace{0.5em}
\hrule
\vspace{0.5em}

Finally, a common pattern when defining recursive process-polymorphic functions has the same processes at every recursive call.
For instance, consider the following pseudocode, which takes a tree that contains $A$'s data and returns a tree that contains that same data at $B$, with $A$ sending all of the data to $B$ one at a time:
$$
\begin{array}{l}
  \programfont{function}~\programfont{tree\_send} (A, B, t) \coloneqq \\
  \quad\begin{array}[t]{@{}l@{}}
    \programfont{match}~t~\programfont{with}\\
    {} \mid \programfont{Leaf} \Rightarrow \programfont{Leaf}\\
    {} \mid \programfont{Branch}(l, A.x, r) \Rightarrow \programfont{Branch}(\programfont{tree\_send}(A, B, l), A.x \rightsquigarrow B, \programfont{tree\_send}(A,B,r))
  \end{array}
\end{array}
$$
Note that every recursive call to \programfont{tree\_send} has the same process parameters as the original call.
EPP must insert a \AmIN instruction at the beginning of the function.
Na\"ively, this requires that the relevant processes incur a cost at every recursive call.
However, because the participants never change in this loop, we can instead remove this \AmIN instruction from the beginning of the recursive calls.
To do so, we compile the function to multiple different recursive functions depending on whether the current process is one of the parameters.
The main body of the function, then, simply selects which version of the function to run.
This again leads to an exponential blowup in code size, though the static analysis described above should also prevent that blowup in common cases.

For each of these three optimizations, we plan to prove that the resulting version of EPP is deadlock free.
The code-size and performance savings, however, will usually be common-case, rather than worst case.
We therefore plan to validate these metrics empirically.
In order to do so, we need a benchmark for process-polymorphic EPP and an implementation of our optimizations.

\begin{goal}
  Develop a benchmark suite for process-polymorphic EPP.
\end{goal}

We plan to develop a benchmark of programs that make use of process polymorphism in order to validate choreographic compilers.
In particular, we plan to include in our benchmarks the worst-case example sketched above as well as programs designed to be amenable to optimization.
We would like the bulk of the benchmark to be ``representative'' examples of process-polymorphic code.
Since process polymorphism is so new, this would require creating a large repository of process-polymorphic code in order to discover how it is used in practice.

\begin{goal}
  Implement an optimizing version of process-polymorphic EPP.
  Use it to experimentally validate our optimizations.
\end{goal}

PI~Hirsch has preliminary work in the form of a compiler for a functional choreographic programming language.
This compiler has been built in no small part by a team of undergraduate students participating in SUNY~Buffalo's \emph{Experiential Learning and Research~(ELR)} program.
This program allows students to complete a significant portion of their degree by participating in small teams under a professor's (or industrial ``client's'') direction on a long-term project for three semesters.
PI~Hirsch's team has recently graduated its first group of students, and currently has students on their first and second semesters.
They design and develop the compiler under the direction of PI~Hirsch and his team of graduate students.

We plan to develop the compiler by adding in process polymorphism in both the optimized and the unoptimized form.
This will be performed by a combination of graduate and undergraduate students.
Moreover, the undergraduate students will implement the benchmark suite of process-polymorphic programs described above.
This will not only allow us to experimentally verify our optimizations, but also (further) train undergraduate students in compiler design, functional programming, and experimental practice.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "desc"
%%% End:
