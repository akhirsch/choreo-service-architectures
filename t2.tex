%thrust2
\subsection{Thrust 2: Improved Compilation for Process Polymorphism}
\label{sec:t2}

\iffalse
\begin{outline}{Thrust 2 Outline}
\item Current status of Process Polymorphism
  \begin{lvl}
  \item Trick in EPP: Autognosis
    \begin{lvl}
    \item Every process knows its own identity
    \end{lvl}
  \item Formalized as $\AmIinN$
    \begin{lvl}
    \item Branches depending on whether the current process is in some set
    \end{lvl}
  \item Current state of the art: \emph{every} process-polymorphic function introduces $\AmIinN$ everywhere.
  \end{lvl}
\item Critique
  \begin{lvl}
  \item Every process-polymorphic function has its code doubled
    \begin{lvl}
    \item Can lead to expondential blowup of code size
    \item Linear cost to performance
    \end{lvl}
  \item This seems to be inherent for worst-case
    \begin{lvl}
    \item Random paths example
    \end{lvl}
  \item Often, it is unnecessary
  \end{lvl}
\item Goal: Cheap Process Polymorphism
  \begin{lvl}
  \item Static analyis
    \begin{lvl}
    \item Must
    \item Might
    \end{lvl}
  \item Switch-case $\programfont{AmI}\mathord{\in}\programfont{?}$
    \begin{lvl}
    \item Make statically-known disjoint sets flat
    \item Do they need to be disjoint?
      \begin{lvl}
      \item First-match semantics
      \end{lvl}
    \end{lvl}
  \end{lvl}
\item Experimental Verification of Efficiency Gains
  \begin{lvl}
  \item Goal: Develop benchmarks for process polymorphic EPP
    \begin{lvl}
    \item Contains worst-case example
    \item Contains examples that our techniques can optimize
    \item Contains ``representative'' examples
    \end{lvl}
  \item Goal: Build new EPP into compiler
    \begin{lvl}
    \item Undergraduate training
    \item Prior Work
    \end{lvl}
  \item Results of our benchmark
    \begin{lvl}
    \item Goal: Experimentally verify our optimizations are useful in practice.
    \end{lvl}
  \end{lvl}
\end{outline}
\fi

Improving compilation requires both designing improved techniques and validating the improvements.
Compilation of process-polymorphic choreographies lacks both effective optimization techniques and any sort of benchmark for effectiveness.
In this thrust, we propose to address both missing pieces.

\subsubsection{Removing Unnecessary Identity Checks}

As mentioned above, choreographic programs are compiled through an operation known as \emph{endpoint projection~(EPP)}, which extracts a program for each participant in the system.
To implement process polymorphism, EPP relies on the principle of \emph{autognosis}: every participant knows their own identity.
This is formalized in the network language via a primitive $\AmIN$ operation~\cite{GraversenHM24},
which branches based on the relationship between the current party and a given value.
For instance, $\AmI{\ell}{C_1}{C_2}$ means ``if the party running this program has name~$\ell$, run~$C_1$, otherwise run~$C_2$.''
The PIs have generalized this to \AmIinN, which tests if the running program's name is in a given set~\citep{SamuelsonHC25}.

In current choreographic theory, \emph{every} process-polymorphic function starts with as many $\AmIN$/$\AmIinN$ operations as there are process parameters.
This approach can produce an exponential blowup in code size---the projection of a process-polmorphic function with~$k$ process parameters will have $2^k$ copies of the code.
Moreover, these branches have a (small) cost at runtime, leading to a linear performance cost.

In the worst case, this cost in both code size and performance appears inherent.
For instance, consider the following choreographic pseudocode:
\newcommand{\RandSets}{\programfont{randomSubsets}}
\[
%  \def\arraystretch{1.1}
%  \newcommand{\Weird}{\programfont{weird}}
%  \begin{array}{l}
%    (\rho_1, \rho_2) \ChorDef \programfont{randomSplit}(\{\Alice, \Bob, \Cathy, \Dave\}) \\
%    \Weird \ChorDef \TLamN (\alpha, \beta)\ldotp (\alpha.1, \beta.2) \\
%    \ITE{\programfont{flip}()}{\Weird(\rho_1, \rho_2)}{\Weird(\rho_2, \rho_1)}
%  \end{array}
  \LetIn{(\rho_1, \rho_2, \rho_3)}{\RandSets(\{\Alice, \Bob, \Cathy, \Dave\})}{(\rho_1.1, \rho_2.2, \rho_3.3)}
\]
This program randomly splits the set of participants $\{\Alice, \Bob, \Cathy, \Dave\}$ into three dynamic sets, $\rho_1$,~$\rho_2$, and~$\rho_3$, potentially with overlap.
For each of~$i = 1, 2, 3$, locations in~$\rho_i$ produce the value~$i$.
%Locations in~$\rho_1$ then produce the value~$1$ and locations in~$\rho_2$ produce~$2$.
%It then randomly chooses one of these two dynamic sets to get the value $1$, while the other gets the value $2$.
Since any participant could end up in any~$\rho_i$ independently, and which set they are in is only determined at runtime, everyone must have eight code paths:
one for each possible combination of being in~$\rho_1$, $\rho_2$, and/or~$\rho_3$.
%one each for when they are in only~$\rho_1$, only~$\rho_2$, both, or neither.

While this example shows that the current (na\"ive) solution is optimal in some cases, it is not always.
In fact, relatively common use cases of process polymorphism only select between a few possible inputs.
We can already see this in the above example.
A process $\LocFont{E}$ that is not any of~\Alice, \Bob, \Cathy, or~\Dave does \emph{not} need multiple code paths.
We statically know it cannot be in any of~$\rho_1$,~$\rho_2$, or~$\rho_3$.
Similarly, if we replaced \RandSets with a partitioning function,
\Alice,~\Bob, \Cathy, and~\Dave would each only need three code paths.

Using existing binary \AmIN statements creates a nested branching structure that is challenging to analyze.
We therefore propose a simplified multi-way \AmIN analogous to \programfont{switch}--\programfont{case} flattening multi-branch \programfont{if} statement.
%Even when we do need an \AmIN instruction, however, we may be able to do better by allowing multi-way \AmIN expressions analogous to \programfont{switch} statements vis-a-vis \programfont{if} statements.
For instance, the body of the \LetN in the above example could project to the following.
\[
  \AmIinN \begin{array}[t]{@{}l@{}}
    {}\mid \rho_1 \cap \rho_2 \cap \rho_3 \Rightarrow (1, 2, 3) \\
    {}\mid \rho_1 \cap \rho_2 \Rightarrow (1, 2) \\
    \quad \vdots \\
    {}\mid \rho_2 \Rightarrow 2 \\
    {}\mid \rho_3 \Rightarrow 3 \\
    {}\mid \_ \Rightarrow () \\
  \end{array}
\]
While this may not provide significant benefit for this intentionally-contrived worse-case example,
its value becomes clear if we, say, replace \RandSets with a partitioning function that guarantees~$\rho_1$, $\rho_2$, and~$\rho_3$ are all disjoint.
In that situation, each intersection of two or more $\rho_i$'s must be empty, meaning no location is in~$\rho_1 \cap \rho_2$.
Those options can then be removed entirely, leaving only four branches for~\Alice, \Bob, \Cathy, and~\Dave, and the constant~$()$ for everyone else.

\ethan{
  I was having trouble buying that the switch-case formulation is actually different from the first optimization.
  I tried to tie it together as an important component of implementing it properly.
}

These ideas lead to the following goal:
\begin{goal}
  Create an optimized version of endpoint projection leveraging multi-way \AmIN
  to produce smaller program sizes and better run-time performance in common cases.
\end{goal}

To achieve this goal, we propose to employ static analysis to determine which participants a name might represent and which participants might be in a set.
In the example above, \RandSets is provided the constant set $\{\Alice, \Bob, \Cathy, \Dave\}$ as an argument,
so those are the only locations that can be in~$\rho_1$, $\rho_2$, and~$\rho_3$.
Note that tracking this information through polymorphic function calls becomes considerably more complicated.

We propose to investigate multiple static analysis techniques in the literature that appear suited to provide the information needed for this optimization.
In particular, abstract interpretation~\todo{cite Cousot and Cousot?}, type-and-effect systems~\todo{cite},
and refinement types~\todo{cite} can all track which locations might be in a given set.
We plan to investigate each as possibilities.
By providing EPP with information about which locations might be in each set,
we can optimize the projection to only produce necessary \AmIN statements,
avoiding both code blowup and unnecessary performance costs.

%To achieve this goal, we will need to employ static analysis to determine which participants a name might represent and which participants might be in a set.
%In the case of the example above, we know that only the four participants $A$, $B$, $C$, and $D$ could possibly be in $\rho_1$ and $\rho_2$.
%Moreover, since \programfont{weird} is only called with $\rho_1$ and $\rho_2$ as arguments, $X$ and $Y$ have the same restrictions.
%(Note that this requires knowledge about the entire scope of \programfont{weird}: without that knowledge, $X$ and $Y$ could include any participant.)
%Several static analysis methods in the literature seem to be able to give us the information required for this optimization.
%In particular, abstract interpretation and type-and-effect systems both seem to be plausible candidates.
%We plan to investigate both as possibilities.
%Once we have the information about who \emph{could} be represented by a name/set of names, we can then use that during projection to only project \AmIN instructions when necessary.
%This will prevent code blowup in many cases, as well as linear costs that do not need to be paid.

\paragraph{Redundant Identity Checks}
\ethan{Can we move this up above the goal statement?}
Another significant gain can come from removing redundant identity checks.
A common pattern where they arise is recursive process-polymorphic functions that use the same process at every recursive call.
For instance, consider the following function that takes a tree with data at location variable~$\alpha$
and returns a tree with the same data at~$\beta$, sending the data one piece at a time.
\[
  \newcommand{\TreeSend}{\programfont{tree\_send}}
  \Fun{\TreeSend}{\alpha, \beta, T}{%
    \begin{array}[t]{@{}l@{}}
      \ChorFont{match}~T~\ChorFont{with} \\
      {}\mid \programfont{Leaf} \Rightarrow \programfont{Leaf} \\
      {}\mid \programfont{Node}(L, \alpha.x, R) \Rightarrow \programfont{Node}(
      \begin{array}[t]{@{}l@{}}
        \TreeSend(\alpha, \beta, L), \\
        \alpha.x \ColSend \beta, \\
        \TreeSend(\alpha, \beta, R))
      \end{array}
    \end{array}
  }
\]
Note that every recursive call to \programfont{tree\_send} has the same process parameters as the original call.
Existing EPP definitions simply insert \AmIN instructions at the beginning of the recursive function,
meaning the relevant process must verify its identity on every recursive call.
However, the participants never change.
The first \AmIN check is necessary, but every subsequent check will produce the same result.

We propose to eliminate these sorts of redundancies.
For recursive polymorphic functions, we can compile to two different non-polymorphic recursive functions,
one where the location variable resolves to the current party and one where it does not.
The full function then uses a single \AmIN to select which non-polymorphic function to execute.
While this may appear to lead to the same exponential code blowup as existing na\"ive uses of \AmIN,
it is simply shifting the code expansion from inside the polymorphic function to outside.
Moreover, the static analysis proposed above is, again, precisely the solution to mitigate any concern.

\akh{It feels like we set up a punchline here but never said it.
  I think the big thing we need to say is that ``this will remove a dynamic check at every recursive call, eliminating a significant runtime penalty'' or something like that.'}

\subsubsection{Benchmarking Compilation Performance}
\ethan{I haven't gotten to editing this yet.}

For each of these three optimizations, we plan to prove that the resulting version of EPP is deadlock free.
The code-size and performance savings, however, will usually be common-case, rather than worst case.
We therefore plan to validate these metrics empirically.
In order to do so, we need a benchmark for process-polymorphic EPP and an implementation of our optimizations.

\begin{goal}
  Develop a benchmark suite for process-polymorphic EPP.
\end{goal}

We plan to develop a benchmark of programs that make use of process polymorphism in order to validate choreographic compilers.
In particular, we plan to include in our benchmarks the worst-case example sketched above as well as programs designed to be amenable to optimization.
We would like the bulk of the benchmark to be ``representative'' examples of process-polymorphic code.
Since process polymorphism is so new, this would require creating a large repository of process-polymorphic code in order to discover how it is used in practice.

\begin{goal}
  Implement an optimizing version of process-polymorphic EPP.
  Use it to experimentally validate our optimizations.
\end{goal}

PI~Hirsch has preliminary work in the form of a compiler for a functional choreographic programming language.
This compiler has been built in no small part by a team of undergraduate students participating in SUNY~Buffalo's \emph{Experiential Learning and Research~(ELR)} program.
This program allows students to complete a significant portion of their degree by participating in small teams under a professor's (or industrial ``client's'') direction on a long-term project for three semesters.
PI~Hirsch's team has recently graduated its first group of students, and currently has students on their first and second semesters.
They design and develop the compiler under the direction of PI~Hirsch and his team of graduate students.

We plan to develop the compiler by adding in process polymorphism in both the optimized and the unoptimized form.
This will be performed by a combination of graduate and undergraduate students.
Moreover, the undergraduate students will implement the benchmark suite of process-polymorphic programs described above.
This will not only allow us to experimentally verify our optimizations, but also (further) train undergraduate students in compiler design, functional programming, and experimental practice.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "desc"
%%% End:
